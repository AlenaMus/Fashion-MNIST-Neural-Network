{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Experiments & Custom Loss Functions\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook explores two key questions:\n",
    "\n",
    "1. **How does the loss function affect learning?** We build a custom loss that penalizes large weights and find criteria to improve it.\n",
    "2. **How does network architecture affect accuracy?** We compare 4 different architectures side-by-side.\n",
    "\n",
    "### Part A: Regularization Strategy Comparison\n",
    "\n",
    "We test 5 loss function strategies on the baseline (512→256→10) architecture:\n",
    "\n",
    "| # | Strategy | Loss Formula | Purpose |\n",
    "|---|----------|-------------|----------|\n",
    "| 1 | No Regularization | `CE(y, ŷ)` | Baseline — pure crossentropy |\n",
    "| 2 | L2 Weight Decay | `CE + λ∑(wᵢ²)` | Keeps all weights small |\n",
    "| 3 | L1 Sparsity | `CE + λ∑|wᵢ|` | Drives unimportant weights to zero |\n",
    "| 4 | Elastic Net (L1+L2) | `CE + λ₁∑|wᵢ| + λ₂∑(wᵢ²)` | Combines sparsity + stability |\n",
    "| 5 | L2 + Label Smoothing | `smooth_CE + λ∑(wᵢ²)` | Weight penalty + calibrated outputs |\n",
    "\n",
    "### Part B: Architecture Comparison\n",
    "\n",
    "Using the best loss from Part A, we compare:\n",
    "\n",
    "| # | Name | Architecture | Rationale |\n",
    "|---|------|-------------|----------|\n",
    "| 1 | Baseline | 512 → 256 → 10 | Our original model |\n",
    "| 2 | Narrow | 128 → 64 → 10 | Fewer parameters |\n",
    "| 3 | Deep | 512 → 256 → 128 → 64 → 10 | More layers |\n",
    "| 4 | Wide | 1024 → 512 → 256 → 10 | More neurons per layer |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup — Imports, GPU, Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "SECTION 1: SETUP — Imports, GPU, Data Loading & Preprocessing\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Reproducibility ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# --- GPU Configuration ---\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\nGPU Available: {len(gpus)} device(s) detected\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  -> {gpu.name}\")\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"  Memory growth enabled\")\n",
    "else:\n",
    "    print(\"\\nWARNING: No GPU detected! Training will run on CPU (slower).\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- Class Names ---\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "# --- Load & Preprocess Data ---\n",
    "print(\"\\nLoading Fashion MNIST dataset...\")\n",
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = fashion_mnist.load_data()\n",
    "print(f\"  Training: {X_train_raw.shape[0]} images | Test: {X_test_raw.shape[0]} images\")\n",
    "\n",
    "X_train = X_train_raw.astype('float32') / 255.0\n",
    "X_test = X_test_raw.astype('float32') / 255.0\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "y_train = to_categorical(y_train_raw, num_classes=10)\n",
    "y_test = to_categorical(y_test_raw, num_classes=10)\n",
    "\n",
    "print(f\"  X_train: {X_train.shape} | y_train: {y_train.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}  | y_test:  {y_test.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Custom Loss Function — Weight Regularization\n",
    "\n",
    "### The Problem with Standard Cross-Entropy\n",
    "\n",
    "The standard loss function only cares about prediction accuracy:\n",
    "\n",
    "```\n",
    "Loss = CrossEntropy(y_true, y_pred) = -∑(y_true × log(y_pred))\n",
    "```\n",
    "\n",
    "This allows the model to develop **very large weights** to fit the training data perfectly, which leads to **overfitting** — the model memorizes training examples instead of learning general patterns.\n",
    "\n",
    "### Solution: Add a Weight Penalty to the Loss\n",
    "\n",
    "We modify the loss function to include a **regularization term** that penalizes large weights:\n",
    "\n",
    "```\n",
    "Loss = CrossEntropy(y_true, y_pred) + λ × Regularization(weights)\n",
    "```\n",
    "\n",
    "Where **λ** (lambda) controls the strength of the penalty. The regularization term forces the optimizer to find a solution that is both accurate AND has small weights.\n",
    "\n",
    "#### L2 Regularization (Weight Decay)\n",
    "```\n",
    "Loss = CE + λ × ∑(wᵢ²)\n",
    "```\n",
    "- Penalizes the **sum of squared weights**\n",
    "- Large weights get penalized heavily (quadratic penalty)\n",
    "- Keeps all weights small but rarely makes them exactly zero\n",
    "- Most common regularization method\n",
    "\n",
    "#### In Keras\n",
    "\n",
    "Weight regularization is applied via `kernel_regularizer` on each Dense layer. Keras automatically adds the regularization loss to the total loss during training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "SECTION 2: MODEL BUILDER WITH WEIGHT REGULARIZATION\n",
    "=============================================================================\n",
    "build_model()  — creates a Sequential model with optional weight regularization\n",
    "train_and_evaluate() — compiles, trains, and evaluates a model\n",
    "\"\"\"\n",
    "\n",
    "def build_model(layer_sizes, reg_type=None, reg_lambda=1e-4):\n",
    "    \"\"\"\n",
    "    Build a Sequential model with optional weight regularization.\n",
    "\n",
    "    The regularization penalty is added to the loss function automatically:\n",
    "      - L2:    Loss += lambda * sum(w_i^2)       -> keeps weights small\n",
    "      - L1:    Loss += lambda * sum(|w_i|)        -> encourages zero weights\n",
    "      - L1_L2: Loss += l1*sum(|w_i|) + l2*sum(w_i^2)  -> elastic net\n",
    "\n",
    "    Args:\n",
    "        layer_sizes: list of ints, e.g. [512, 256, 10]\n",
    "        reg_type: None, 'l2', 'l1', or 'l1_l2'\n",
    "        reg_lambda: regularization strength (float)\n",
    "    \"\"\"\n",
    "    if reg_type == 'l2':\n",
    "        kernel_reg = regularizers.l2(reg_lambda)\n",
    "    elif reg_type == 'l1':\n",
    "        kernel_reg = regularizers.l1(reg_lambda)\n",
    "    elif reg_type == 'l1_l2':\n",
    "        kernel_reg = regularizers.l1_l2(l1=reg_lambda, l2=reg_lambda)\n",
    "    else:\n",
    "        kernel_reg = None\n",
    "\n",
    "    layers = []\n",
    "    for i, units in enumerate(layer_sizes):\n",
    "        is_output = (i == len(layer_sizes) - 1)\n",
    "        if is_output:\n",
    "            layers.append(Dense(units, activation='softmax'))\n",
    "        else:\n",
    "            kwargs = {'activation': 'relu'}\n",
    "            if i == 0:\n",
    "                kwargs['input_shape'] = (784,)\n",
    "            if kernel_reg is not None:\n",
    "                kwargs['kernel_regularizer'] = kernel_reg\n",
    "            layers.append(Dense(units, **kwargs))\n",
    "            layers.append(Dropout(0.2))\n",
    "\n",
    "    return Sequential(layers)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, label_smoothing=0.0, epochs=20, batch_size=128):\n",
    "    \"\"\"\n",
    "    Compile, train, and evaluate a model. Returns results dict.\n",
    "    \"\"\"\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "        label_smoothing=label_smoothing\n",
    "    )\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'params': model.count_params(),\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'train_time': train_time,\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"build_model() and train_and_evaluate() defined.\")\n",
    "print(\"\\nExample — build_model([512, 256, 10], reg_type='l2', reg_lambda=1e-4)\")\n",
    "print(\"This creates: Dense(512,ReLU,L2) -> Dropout -> Dense(256,ReLU,L2) -> Dropout -> Dense(10,Softmax)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Criteria for Improving the Loss Function\n",
    "\n",
    "Starting from our custom loss `Loss = CE + λ∑(w²)`, we identified **4 criteria** to improve it:\n",
    "\n",
    "### Criterion 1: L1 Regularization (Sparsity)\n",
    "```\n",
    "Loss = CE + λ × ∑|wᵢ|\n",
    "```\n",
    "- Drives **unimportant weights to exactly zero** (sparse network)\n",
    "- Effectively performs **automatic feature selection**\n",
    "- Results in a simpler, more interpretable model\n",
    "- Risk: Can be unstable during training if λ is too large\n",
    "\n",
    "### Criterion 2: Elastic Net (L1 + L2 combined)\n",
    "```\n",
    "Loss = CE + λ₁∑|wᵢ| + λ₂∑(wᵢ²)\n",
    "```\n",
    "- **Combines the benefits** of L1 (sparsity) and L2 (stability)\n",
    "- L2 handles **correlated features** better than L1 alone\n",
    "- L1 still zeros out truly unimportant weights\n",
    "- More robust than using either alone\n",
    "\n",
    "### Criterion 3: Label Smoothing\n",
    "Instead of hard targets `[0, 0, 1, 0, ...]`, use soft targets `[0.01, 0.01, 0.91, 0.01, ...]`\n",
    "```\n",
    "y_smooth = y_true × (1 - ε) + ε / num_classes\n",
    "```\n",
    "- Prevents the model from becoming **overconfident** in predictions\n",
    "- Improves **probability calibration** (confidence matches actual accuracy)\n",
    "- Acts as regularization on the **output distribution**\n",
    "- Typically ε = 0.1 (10% smoothing)\n",
    "\n",
    "### Criterion 4: Combined Strategy (L2 + Label Smoothing)\n",
    "```\n",
    "Loss = SmoothCE(y, ŷ, ε=0.1) + λ∑(wᵢ²)\n",
    "```\n",
    "- Weight penalty regularizes the **internal representations**\n",
    "- Label smoothing regularizes the **output predictions**\n",
    "- Together they address overfitting from **two different angles**\n",
    "\n",
    "### Experiment\n",
    "\n",
    "We train the baseline architecture (512→256→10) with each strategy and compare test accuracy, loss, and total weight magnitude."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "SECTION 3: REGULARIZATION STRATEGY COMPARISON\n",
    "=============================================================================\n",
    "Train baseline architecture (512 -> 256 -> 10) with 5 different loss\n",
    "function strategies and compare results.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART A: REGULARIZATION STRATEGY COMPARISON\")\n",
    "print(\"Architecture: 512 -> 256 -> 10 (Baseline)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "baseline_arch = [512, 256, 10]\n",
    "\n",
    "reg_configs = [\n",
    "    {'name': 'No Regularization',       'reg_type': None,    'reg_lambda': 0,      'label_smoothing': 0.0},\n",
    "    {'name': 'L2 (lambda=1e-4)',         'reg_type': 'l2',    'reg_lambda': 1e-4,   'label_smoothing': 0.0},\n",
    "    {'name': 'L1 (lambda=1e-5)',         'reg_type': 'l1',    'reg_lambda': 1e-5,   'label_smoothing': 0.0},\n",
    "    {'name': 'Elastic Net (L1+L2)',      'reg_type': 'l1_l2', 'reg_lambda': 1e-5,   'label_smoothing': 0.0},\n",
    "    {'name': 'L2 + Label Smoothing',     'reg_type': 'l2',    'reg_lambda': 1e-4,   'label_smoothing': 0.1},\n",
    "]\n",
    "\n",
    "reg_results = []\n",
    "\n",
    "for cfg in reg_configs:\n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(f\"Training: {cfg['name']}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Reset seeds for fair comparison\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "    m = build_model(baseline_arch, reg_type=cfg['reg_type'], reg_lambda=cfg['reg_lambda'])\n",
    "    res = train_and_evaluate(m, label_smoothing=cfg['label_smoothing'])\n",
    "    res['name'] = cfg['name']\n",
    "\n",
    "    # Compute total weight magnitude for analysis\n",
    "    total_weight_norm = sum(float(tf.reduce_sum(tf.square(w)).numpy())\n",
    "                           for w in m.trainable_weights if 'kernel' in w.name)\n",
    "    res['weight_norm'] = total_weight_norm\n",
    "\n",
    "    reg_results.append(res)\n",
    "    print(f\"  Test Accuracy: {res['test_accuracy']:.4f} | \"\n",
    "          f\"Weight Norm: {total_weight_norm:.2f} | \"\n",
    "          f\"Time: {res['train_time']:.1f}s\")\n",
    "\n",
    "# --- Comparison Table ---\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"REGULARIZATION COMPARISON RESULTS\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Strategy':<25s} {'Params':>10s} {'Test Acc':>10s} {'Test Loss':>10s} \"\n",
    "      f\"{'W. Norm':>10s} {'Time (s)':>10s}\")\n",
    "print(\"-\" * 90)\n",
    "for r in reg_results:\n",
    "    print(f\"{r['name']:<25s} {r['params']:>10,d} {r['test_accuracy']:>10.4f} \"\n",
    "          f\"{r['test_loss']:>10.4f} {r['weight_norm']:>10.2f} {r['train_time']:>10.1f}\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "best_reg = max(reg_results, key=lambda x: x['test_accuracy'])\n",
    "print(f\"\\nBest regularization strategy: {best_reg['name']} \"\n",
    "      f\"with {best_reg['test_accuracy']*100:.2f}% test accuracy\")\n",
    "\n",
    "# --- Charts ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "fig.suptitle('Regularization Strategy Comparison (Baseline Architecture)',\n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Chart 1: Test Accuracy\n",
    "names_r = [r['name'] for r in reg_results]\n",
    "accs_r = [r['test_accuracy'] for r in reg_results]\n",
    "colors_r = ['#2ecc71' if r is best_reg else '#3498db' for r in reg_results]\n",
    "axes[0].barh(names_r, accs_r, color=colors_r, edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Test Accuracy', fontsize=12)\n",
    "axes[0].set_title('Test Accuracy', fontsize=13, fontweight='bold')\n",
    "for i, acc in enumerate(accs_r):\n",
    "    axes[0].text(acc + 0.001, i, f'{acc:.4f}', va='center', fontsize=10, fontweight='bold')\n",
    "axes[0].set_xlim([min(accs_r) - 0.01, max(accs_r) + 0.015])\n",
    "\n",
    "# Chart 2: Weight Norms\n",
    "norms = [r['weight_norm'] for r in reg_results]\n",
    "axes[1].barh(names_r, norms, color='#e74c3c', edgecolor='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('Sum of Squared Weights', fontsize=12)\n",
    "axes[1].set_title('Weight Norm (smaller = simpler model)', fontsize=13, fontweight='bold')\n",
    "for i, n in enumerate(norms):\n",
    "    axes[1].text(n + max(norms)*0.01, i, f'{n:.1f}', va='center', fontsize=10)\n",
    "\n",
    "# Chart 3: Validation Accuracy Curves\n",
    "style_map = [('blue', '-'), ('orange', '--'), ('green', '-.'), ('red', ':'), ('purple', '-')]\n",
    "for i, r in enumerate(reg_results):\n",
    "    c, ls = style_map[i]\n",
    "    axes[2].plot(r['history'].history['val_accuracy'], label=r['name'],\n",
    "                 color=c, linestyle=ls, linewidth=2)\n",
    "axes[2].set_title('Validation Accuracy Over Epochs', fontsize=13, fontweight='bold')\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "axes[2].legend(fontsize=8, loc='lower right')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "=============================================================================\n",
    "SECTION 4: ARCHITECTURE COMPARISON (with best regularization)\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "# Determine best regularization config\n",
    "best_reg_cfg = reg_configs[reg_results.index(best_reg)]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART B: ARCHITECTURE COMPARISON\")\n",
    "print(f\"Using best loss: {best_reg['name']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "arch_configs = [\n",
    "    {'name': 'Baseline (512-256)',       'layers': [512, 256, 10]},\n",
    "    {'name': 'Narrow (128-64)',          'layers': [128, 64, 10]},\n",
    "    {'name': 'Deep (512-256-128-64)',    'layers': [512, 256, 128, 64, 10]},\n",
    "    {'name': 'Wide (1024-512-256)',      'layers': [1024, 512, 256, 10]},\n",
    "]\n",
    "\n",
    "arch_results = []\n",
    "\n",
    "for arch in arch_configs:\n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(f\"Training: {arch['name']}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Reset seeds for fair comparison\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "    m = build_model(arch['layers'],\n",
    "                    reg_type=best_reg_cfg['reg_type'],\n",
    "                    reg_lambda=best_reg_cfg['reg_lambda'])\n",
    "    res = train_and_evaluate(m, label_smoothing=best_reg_cfg['label_smoothing'])\n",
    "    res['name'] = arch['name']\n",
    "    arch_results.append(res)\n",
    "    print(f\"  Test Accuracy: {res['test_accuracy']:.4f} | \"\n",
    "          f\"Params: {res['params']:,} | Time: {res['train_time']:.1f}s\")\n",
    "\n",
    "# --- Architecture Comparison Table ---\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ARCHITECTURE COMPARISON RESULTS\")\n",
    "print(f\"(All using: {best_reg['name']})\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model':<25s} {'Params':>10s} {'Test Acc':>10s} {'Test Loss':>10s} {'Time (s)':>10s}\")\n",
    "print(\"-\" * 80)\n",
    "for r in arch_results:\n",
    "    print(f\"{r['name']:<25s} {r['params']:>10,d} {r['test_accuracy']:>10.4f} \"\n",
    "          f\"{r['test_loss']:>10.4f} {r['train_time']:>10.1f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_arch = max(arch_results, key=lambda x: x['test_accuracy'])\n",
    "print(f\"\\nBest architecture: {best_arch['name']} \"\n",
    "      f\"with {best_arch['test_accuracy']*100:.2f}% test accuracy\")\n",
    "\n",
    "# --- Charts ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle(f'Architecture Comparison (Loss: {best_reg[\"name\"]})',\n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "names_a = [r['name'] for r in arch_results]\n",
    "accs_a = [r['test_accuracy'] for r in arch_results]\n",
    "colors_a = ['#2ecc71' if r is best_arch else '#3498db' for r in arch_results]\n",
    "axes[0].bar(names_a, accs_a, color=colors_a, edgecolor='black', linewidth=0.5)\n",
    "axes[0].set_title('Test Accuracy by Architecture', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Test Accuracy', fontsize=12)\n",
    "axes[0].set_ylim([min(accs_a) - 0.02, max(accs_a) + 0.02])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, acc in enumerate(accs_a):\n",
    "    axes[0].text(i, acc + 0.003, f'{acc:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Validation accuracy curves\n",
    "style_map_a = [('blue', '-'), ('orange', '--'), ('green', '-.'), ('red', ':')]\n",
    "for i, r in enumerate(arch_results):\n",
    "    c, ls = style_map_a[i]\n",
    "    axes[1].plot(r['history'].history['val_accuracy'], label=r['name'],\n",
    "                 color=c, linestyle=ls, linewidth=2)\n",
    "axes[1].set_title('Validation Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# EXPERIMENT SUMMARY\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nBest regularization: {best_reg['name']}\")\n",
    "print(f\"  -> Test accuracy: {best_reg['test_accuracy']*100:.2f}%\")\n",
    "print(f\"  -> Weight norm:   {best_reg['weight_norm']:.2f}\")\n",
    "print(f\"\\nBest architecture:  {best_arch['name']}\")\n",
    "print(f\"  -> Test accuracy: {best_arch['test_accuracy']*100:.2f}%\")\n",
    "print(f\"  -> Parameters:    {best_arch['params']:,}\")\n",
    "print(f\"  -> Training time: {best_arch['train_time']:.1f}s\")\n",
    "print(f\"\\nConclusion:\")\n",
    "print(f\"  The combination of {best_reg['name']} loss function\")\n",
    "print(f\"  with {best_arch['name']} architecture achieved the best results.\")\n",
    "print(\"=\" * 70)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}